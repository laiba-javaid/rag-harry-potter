{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a475d770",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "%pip install chromadb langchain datasets sentence-transformers groq gradio huggingface_hub\n",
    "%pip install -U langchain-community\n",
    "\n",
    "# Import libraries\n",
    "from huggingface_hub import login, hf_hub_download\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "import requests\n",
    "import gradio as gr\n",
    "import os\n",
    "\n",
    "# Login to Hugging Face\n",
    "login(\"your-hf-token-here\")\n",
    "\n",
    "# Load Harry Potter books\n",
    "print(\"üìö Loading Harry Potter books from text files...\")\n",
    "\n",
    "book_files = {\n",
    "    'train': [\n",
    "        \"train/Harry Potter-Book 1-The Sorcerers Stone.txt\",\n",
    "        \"train/Harry Potter-Book 2-The Chamber of Secrets.txt\",\n",
    "        \"train/Harry Potter-Book 3-The Goblet of Fire.txt\",\n",
    "        \"train/Harry Potter-Book 4-The Prisoner of Azkaban.txt\",\n",
    "        \"train/Harry Potter-Book 5-The Order of the Phoenix.txt\"\n",
    "    ],\n",
    "    'validation': [\n",
    "        \"validation/Harry Potter-Book 6-The Half-Blood Prince.txt\"\n",
    "    ],\n",
    "    'test': [\n",
    "        \"test/Harry Potter-Book 7-The Deathly Hallows.txt\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "texts = []\n",
    "book_contents = {}\n",
    "\n",
    "try:\n",
    "    for split, files in book_files.items():\n",
    "        print(f\"\\nüìñ Loading {split} books...\")\n",
    "\n",
    "        for file_path in files:\n",
    "            book_name = file_path.split('/')[-1].replace('.txt', '')\n",
    "            print(f\"  ‚¨áÔ∏è Downloading: {book_name}\")\n",
    "\n",
    "            try:\n",
    "                local_file = hf_hub_download(\n",
    "                    repo_id=\"WutYee/HarryPotter_books_1to7\",\n",
    "                    filename=file_path,\n",
    "                    repo_type=\"dataset\"\n",
    "                )\n",
    "\n",
    "                with open(local_file, 'r', encoding='utf-8', errors='ignore') as f:\n",
    "                    content = f.read()\n",
    "\n",
    "                book_contents[book_name] = content\n",
    "                texts.append(content)\n",
    "\n",
    "                print(f\"    ‚úÖ Loaded {book_name}\")\n",
    "                print(f\"    üìÑ Total characters: {len(content):,}\")\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"    ‚ùå Failed to load {book_name}: {e}\")\n",
    "\n",
    "    print(f\"\\nüéâ Successfully loaded Harry Potter dataset!\")\n",
    "    print(f\"üìä Total books: {len(book_contents)}\")\n",
    "    print(f\"üìä Total text entries: {len(texts)}\")\n",
    "\n",
    "except Exception as main_error:\n",
    "    print(f\"‚ùå Main loading process failed: {main_error}\")\n",
    "\n",
    "    # Fallback: try loading just one book\n",
    "    print(\"\\nüîÑ Trying to load just one book as a test...\")\n",
    "    try:\n",
    "        test_file = hf_hub_download(\n",
    "            repo_id=\"WutYee/HarryPotter_books_1to7\",\n",
    "            filename=\"train/Harry Potter-Book 1-The Sorcerers Stone.txt\",\n",
    "            repo_type=\"dataset\"\n",
    "        )\n",
    "\n",
    "        with open(test_file, 'r', encoding='utf-8', errors='ignore') as f:\n",
    "            content = f.read()\n",
    "\n",
    "        texts = [content]\n",
    "        book_contents = {\"Harry Potter-Book 1-The Sorcerers Stone\": content}\n",
    "\n",
    "        print(f\"‚úÖ Fallback successful! Loaded 1 book with {len(content):,} characters\")\n",
    "\n",
    "    except Exception as fallback_error:\n",
    "        print(f\"‚ùå Fallback also failed: {fallback_error}\")\n",
    "        texts = []\n",
    "\n",
    "# Only proceed if we have texts\n",
    "if not texts:\n",
    "    raise ValueError(\"‚ùå No texts were loaded! Please check your Hugging Face authentication and internet connection.\")\n",
    "\n",
    "# Split texts into chunks\n",
    "print(\"üî® Splitting books into chunks...\")\n",
    "splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "docs = splitter.create_documents(texts)\n",
    "\n",
    "print(f\"‚úÖ Total chunks created: {len(docs)}\")\n",
    "if docs:\n",
    "    print(f\"üß© Sample chunk:\\n{docs[0].page_content[:300]}...\")\n",
    "\n",
    "# Load embedding model\n",
    "print(\"üì• Loading local embedding model (all-MiniLM-L6-v2)...\")\n",
    "embedding = HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
    "\n",
    "# Create vector store\n",
    "print(\"üß† Creating Chroma vector store...\")\n",
    "vectorstore = Chroma.from_documents(documents=docs, embedding=embedding, persist_directory=\"/content/chroma_db\")\n",
    "vectorstore.persist()\n",
    "\n",
    "# Create retriever\n",
    "retriever = vectorstore.as_retriever(search_kwargs={\"k\": 3})\n",
    "print(\"‚úÖ Vectorstore ready and persisted at /content/chroma_db\")\n",
    "\n",
    "# Fixed Groq API function with better error handling\n",
    "def groq_chat(prompt, model=\"llama-3.1-8b-instant\"):\n",
    "    headers = {\n",
    "        \"Authorization\": \"your-api-key-here\",\n",
    "        \"Content-Type\": \"application/json\"\n",
    "    }\n",
    "\n",
    "    payload = {\n",
    "        \"model\": model,\n",
    "        \"messages\": [\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ],\n",
    "        \"max_tokens\": 1000,\n",
    "        \"temperature\": 0.7\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        response = requests.post(\"https://api.groq.com/openai/v1/chat/completions\",\n",
    "                               headers=headers, json=payload, timeout=30)\n",
    "\n",
    "        if response.status_code != 200:\n",
    "            error_msg = f\"Groq API Error {response.status_code}: {response.text}\"\n",
    "            print(f\"‚ùå {error_msg}\")\n",
    "            return f\"Sorry, I encountered an API error: {error_msg}\"\n",
    "\n",
    "        return response.json()[\"choices\"][0][\"message\"][\"content\"]\n",
    "\n",
    "    except requests.exceptions.Timeout:\n",
    "        return \"Sorry, the request timed out. Please try again.\"\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        return f\"Sorry, there was a network error: {str(e)}\"\n",
    "    except KeyError as e:\n",
    "        return f\"Sorry, unexpected response format from API: {str(e)}\"\n",
    "    except Exception as e:\n",
    "        return f\"Sorry, an unexpected error occurred: {str(e)}\"\n",
    "\n",
    "# Fixed RAG pipeline with better error handling\n",
    "def rag_pipeline(query):\n",
    "    try:\n",
    "        # Validate input\n",
    "        if not query or not query.strip():\n",
    "            return \"Please enter a valid question about Harry Potter.\"\n",
    "\n",
    "        # Retrieve relevant documents\n",
    "        context_docs = retriever.get_relevant_documents(query)\n",
    "\n",
    "        if not context_docs:\n",
    "            return \"Sorry, I couldn't find relevant information in the Harry Potter books for your query.\"\n",
    "\n",
    "        # Create context from retrieved documents\n",
    "        context = \"\\n\\n\".join([doc.page_content for doc in context_docs])\n",
    "\n",
    "        # Create prompt\n",
    "        prompt = f\"\"\"You are a Harry Potter expert. Use the following context to answer the user's question accurately and comprehensively.\n",
    "\n",
    "Context:\n",
    "{context}\n",
    "\n",
    "Question: {query}\n",
    "\n",
    "Answer (be specific and reference the books when possible):\"\"\"\n",
    "\n",
    "        # Get response from Groq\n",
    "        response = groq_chat(prompt)\n",
    "        return response\n",
    "\n",
    "    except Exception as e:\n",
    "        error_msg = f\"An error occurred in the RAG pipeline: {str(e)}\"\n",
    "        print(f\"‚ùå {error_msg}\")\n",
    "        return f\"Sorry, {error_msg}\"\n",
    "\n",
    "# Launch Gradio interface\n",
    "print(\"üöÄ Launching chatbot interface...\")\n",
    "\n",
    "# Create the interface with better configuration\n",
    "interface = gr.Interface(\n",
    "    fn=rag_pipeline,\n",
    "    inputs=gr.Textbox(\n",
    "        label=\"Ask a question about Harry Potter\",\n",
    "        placeholder=\"What is Harry's patronus? Who is Sirius Black? Tell me about Hogwarts...\",\n",
    "        lines=2\n",
    "    ),\n",
    "    outputs=gr.Textbox(\n",
    "        label=\"Answer\",\n",
    "        lines=10\n",
    "    ),\n",
    "    title=\"‚ö° Harry Potter RAG Chatbot\",\n",
    "    description=\"Ask questions about the Harry Potter books! This system uses RAG (Retrieval-Augmented Generation) with local embeddings and Groq's LLM.\",\n",
    "    examples=[\n",
    "        \"What is Harry Potter's patronus?\",\n",
    "        \"Who is Sirius Black?\",\n",
    "        \"Tell me about the Triwizard Tournament\",\n",
    "        \"What are the Deathly Hallows?\",\n",
    "        \"Who is Professor Snape?\"\n",
    "    ],\n",
    "    theme=gr.themes.Soft(),\n",
    "    allow_flagging=\"never\"\n",
    ")\n",
    "\n",
    "interface.launch(debug=True, share=True)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
